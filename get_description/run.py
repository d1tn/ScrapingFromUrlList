import csv
import codecs
from datetime import datetime
from urllib.request import urlopen
from bs4 import BeautifulSoup

# URLãŒè¨˜è¼‰ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
input_file_path = 'URLList.txt'

# ç¾åœ¨ã®æ—¥ä»˜ã¨æ™‚åˆ»ã‚’å–å¾—
now = datetime.now()
now_str = now.strftime('%Y%m%d-%H%M')

# çµæœã‚’æ›¸ãå‡ºã™CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã€‚BOMä»˜ãUTF-8ã§æ›¸ãå‡ºã™ãŸã‚ã«codecsã‚’ä½¿ã†ã€‚
output_file_path = f'list_{now_str}.csv'
output_file = codecs.open(output_file_path, 'w', 'utf-8-sig')

# URLã®ãƒªã‚¹ãƒˆã®èª­ã¿è¾¼ã¿
with open(input_file_path, 'r') as f:
    urls = [line.strip() for line in f]

# å„URLã®ãƒšãƒ¼ã‚¸ã‚¿ã‚¤ãƒˆãƒ«,descriptionã®å–å¾—
titles = []
descriptions = []
for url in urls:
    try:
        html = urlopen(url)
        soup = BeautifulSoup(html, 'html.parser')
        titles.append(soup.title.string)
        descriptions.append(soup.find('meta', attrs={'name':'description'})['content'] if soup.find('meta', attrs={'name':'description'}) else 'N/A')

    except Exception as e:
        print(f'ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¦ãŠã‚Šã¾ã™ğŸ¥ºğŸ’¦ğŸ‘‰ {url}: {e}')
        descriptions.append('')


# çµæœã‚’CSVãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãå‡ºã—
writer = csv.writer(output_file)
for url, title, descriptions in zip(urls, titles, descriptions):
    writer.writerow([url, title, descriptions])

# ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¯ãƒ­ãƒ¼ã‚º
output_file.close()
